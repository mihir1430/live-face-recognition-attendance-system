{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ecc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "from flask import Flask, render_template, Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3eb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1b48067",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **`cv2`:** This library, commonly known as OpenCV (Open Source Computer Vision Library), provides a wide range of functions for image processing, video analysis, and computer vision tasks.\n",
    "2. **`numpy`:** NumPy is a fundamental library for numerical computing in Python. It provides efficient array operations, linear algebra functions, and random number generation.\n",
    "3. **`face_recognition`:** This library simplifies face recognition tasks in Python. It offers functions for face detection, face encoding, and face comparison.\n",
    "4. **`os`:** The `os` module provides functions for interacting with the operating system, such as file and directory operations.\n",
    "5. **`datetime`:** This module allows working with date and time objects. It's useful for tasks like time stamping, time differences, and formatting dates.\n",
    "\n",
    "**Overall Purpose**\n",
    "\n",
    "This code snippet imports the necessary tools for building a face recognition system. It will likely involve:\n",
    "\n",
    "- **Loading images:** Using `os` to access and load image files.\n",
    "- **Face detection:** Employing `face_recognition` to identify faces within images.\n",
    "- **Face encoding:** Converting detected faces into numerical representations (encodings) for comparison.\n",
    "- **Face comparison:** Using `face_recognition` to compare encodings of different faces to determine similarity.\n",
    "- **Time stamping:** Using `datetime` to record the time of face recognition events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4d6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to images for attendance\n",
    "path = 'D:\\Face-Recognition-Attendence-main\\Mark Attendence Project\\ImagesAttendence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e0ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bapa.jpg', 'Bill Gates.jpg', 'Elon Musk.jpg', 'Jeff Bezos.jpg', 'maa.jpg', 'Mark Zuckerberg.jpg', 'mihir.JPG']\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce591f",
   "metadata": {},
   "source": [
    "# Breakdown of the Code:\n",
    "\n",
    "1. images = []:\n",
    "\n",
    "This line creates an empty list named images. This list will be used to store image data as we process them.\n",
    "2. classNames = []:\n",
    "\n",
    "Similarly, this line creates an empty list named classNames. This list will store the names associated with each image.\n",
    "3. myList = os.listdir(path):\n",
    "\n",
    "This line uses the os.listdir(path) function to list all files and directories within the specified directory path.\n",
    "The resulting list of filenames is stored in the myList variable.\n",
    "Overall Purpose:\n",
    "\n",
    "This code snippet is typically used as a preliminary step in many image processing and machine learning tasks. It:\n",
    "\n",
    "Initializes data structures: Creates empty lists to store images and their corresponding class labels.\n",
    "Lists files in a directory: Uses os.listdir to get a list of files within a specified directory.\n",
    "Sets the stage for further processing: The myList containing filenames can be used to iterate over images, load them, and potentially preprocess them.\n",
    "Example Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and their corresponding class names\n",
    "for i in myList:\n",
    "    currentImage = cv2.imread(f'{path}/{i}')\n",
    "    images.append(currentImage)\n",
    "    classNames.append(os.path.splitext(i)[0])\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45e6716b",
   "metadata": {},
   "source": [
    "# Breakdown of the Code:\n",
    "\n",
    "This code snippet iterates through a list of image filenames, loads each image, and appends it to a list along with its corresponding class name.\n",
    "\n",
    "**Here's a step-by-step explanation:**\n",
    "\n",
    "1. **Iterate over filenames:**\n",
    "   - The `for i in myList:` loop iterates over each filename `i` in the `myList`.\n",
    "\n",
    "2. **Load the image:**\n",
    "   - `currentImage = cv2.imread(f'{path}/{i}')`:\n",
    "     - Reads the image file specified by the filename `i` from the directory `path`.\n",
    "     - The `f'{path}/{i}'` string formatting constructs the complete image path.\n",
    "     - `cv2.imread` loads the image and returns it as a NumPy array.\n",
    "\n",
    "3. **Append the image to the list:**\n",
    "   - `images.append(currentImage)`:\n",
    "     - Adds the loaded image `currentImage` to the `images` list.\n",
    "\n",
    "4. **Extract and append the class name:**\n",
    "   - `classNames.append(os.path.splitext(i)[0])`:\n",
    "     - `os.path.splitext(i)[0]` extracts the filename without the extension.\n",
    "     - The extracted filename is appended to the `classNames` list. This is often used as the class label for the image.\n",
    "\n",
    "**Overall Purpose:**\n",
    "\n",
    "This code snippet is a common way to load images and their corresponding labels from a directory. It prepares the data for further processing, such as:\n",
    "\n",
    "- **Training a machine learning model:** The images and their class labels can be used to train a model to recognize objects or faces.\n",
    "- **Face recognition:** The images and names can be used to create a database of known faces.\n",
    "- **Image processing tasks:** The images can be further processed for tasks like resizing, cropping, or filtering.\n",
    "\n",
    "By the end of this loop, the `images` list contains a list of NumPy arrays representing the images, and the `classNames` list contains the corresponding class names. This structured data can then be used for various computer vision applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8685c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and encode faces from the images\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        try:\n",
    "            encode = face_recognition.face_encodings(img)[0]\n",
    "            encodeList.append(encode)\n",
    "        except IndexError:\n",
    "            print(\"Face not found in image, skipping:\", img)\n",
    "            continue\n",
    "    return encodeList"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e27b801d",
   "metadata": {},
   "source": [
    "**Breakdown of the Code:**\n",
    "\n",
    "This code defines a function named `findEncodings` that takes a list of images as input and returns a list of face encodings.\n",
    "\n",
    "**Here's a step-by-step explanation:**\n",
    "\n",
    "1. **Initialize an empty list:**\n",
    "   - `encodeList = []`: Creates an empty list to store the face encodings.\n",
    "\n",
    "2. **Iterate over images:**\n",
    "   - `for img in images:`: Iterates over each image in the input list.\n",
    "\n",
    "3. **Convert color space:**\n",
    "   - `img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)`: Converts the image from BGR color space (used by OpenCV) to RGB color space, which is expected by the `face_recognition` library.\n",
    "\n",
    "4. **Find and encode faces:**\n",
    "   - `try-except` block:\n",
    "     - **Find face encodings:**\n",
    "       - `encode = face_recognition.face_encodings(img)[0]`: Uses the `face_recognition` library to find the face encoding in the image. The `[0]` indexing assumes there's only one face in the image.\n",
    "       - `encodeList.append(encode)`: Appends the found encoding to the `encodeList`.\n",
    "     - **Handle exceptions:**\n",
    "       - `except IndexError`: If no face is found in the image, an `IndexError` is raised. The `except` block handles this exception by printing a message and continuing the loop.\n",
    "\n",
    "5. **Return the encoded list:**\n",
    "   - `return encodeList`: Returns the list of face encodings.\n",
    "\n",
    "**Overall Purpose:**\n",
    "\n",
    "This function is designed to process a list of images, detect faces in each image, and convert the detected faces into numerical representations (encodings). These encodings can be used for various face recognition tasks, such as:\n",
    "\n",
    "- **Face comparison:** Comparing encodings of different faces to determine similarity or identity.\n",
    "- **Face recognition:** Identifying individuals in images or video streams.\n",
    "- **Face clustering:** Grouping similar faces together.\n",
    "\n",
    "By using a `try-except` block, the function handles cases where a face might not be detected in an image, preventing potential errors and ensuring smooth execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0de1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Mark Attendence\n",
    "def markAttendece(name):\n",
    "    with open(\"D:\\Face-Recognition-Attendence-main\\Mark Attendence Project\\Attendance.csv\",'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dateSrting = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dateSrting}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6825cfa",
   "metadata": {},
   "source": [
    "## Breakdown of the `markAttendance` function:\n",
    "\n",
    "This function takes a `name` (presumably of the recognized person) as input and updates an attendance CSV file. Here's a step-by-step explanation:\n",
    "\n",
    "1. **Open the attendance file:**\n",
    "   - `with open(\"D:\\Face-Recognition-Attendence-main\\Mark Attendence Project\\Attendance.csv\",'r+') as f:`:\n",
    "     - Opens the attendance CSV file located at the specified path (adjust the path as needed).\n",
    "     - The `'r+'` mode allows both reading and writing to the file.\n",
    "\n",
    "2. **Read existing attendance data:**\n",
    "   - `myDataList = f.readlines()`: Reads all lines from the CSV file and stores them in a list called `myDataList`.\n",
    "\n",
    "3. **Extract existing names:**\n",
    "   - `nameList = []`: Initializes an empty list `nameList` to store names already present in the attendance file.\n",
    "   - `for line in myDataList:`: Iterates through each line in `myDataList`.\n",
    "     - `entry = line.split(',')`: Splits the current line (presumably a comma-separated string) into a list named `entry`.\n",
    "     - `nameList.append(entry[0])`: Assumes the first element in `entry` is the name, and appends it to `nameList`.\n",
    "\n",
    "4. **Check for new attendee:**\n",
    "   - `if name not in nameList:`: Checks if the provided `name` is not already present in the `nameList`.\n",
    "\n",
    "5. **Mark attendance if new:**\n",
    "   - **Inside the `if` block (only executed if name is new):**\n",
    "     - `now = datetime.now()`: Gets the current date and time using `datetime.now()`.\n",
    "     - `dateSrting = now.strftime('%H:%M:%S')`: Formats the current time into a string format (e.g., \"10:20:30\") using `strftime`.\n",
    "     - `f.writelines(f'\\n{name},{dateSrting}')`: Writes a new line to the CSV file with the `name` and the formatted time string, separated by a comma. This effectively marks the attendance of the person.\n",
    "\n",
    "**Overall Purpose:**\n",
    "\n",
    "This function maintains a simple attendance CSV file by recording the name and time of each person who is recognized for the first time. It ensures that a person's attendance is only marked once.\n",
    "\n",
    "**Important Notes:**\n",
    "\n",
    "- Adjust the file path in the `open` statement to match the location of your CSV file.\n",
    "- This is a basic example. You may want to consider enhancing it with features like:\n",
    "    - Handling potential errors during file operations.\n",
    "    - Adding a date column to the CSV file.\n",
    "    - Implementing a more robust attendance marking logic (e.g., marking only within specific timeframes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ba0370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding completed!\n"
     ]
    }
   ],
   "source": [
    "# Get known face encodings\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding completed!')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "469faa53",
   "metadata": {},
   "source": [
    "**Breakdown of the Code:**\n",
    "\n",
    "This code segment is typically used as a preprocessing step in face recognition systems. It:\n",
    "\n",
    "1. **Prepares known faces:** Encodes the faces of known individuals, creating a reference database.\n",
    "2. **Enables comparison:** These encodings can then be compared to the encodings of faces detected in real-time or in other images to identify individuals.\n",
    "\n",
    "**In a broader context of a face recognition system, this step might be followed by:**\n",
    "\n",
    "- **Real-time face detection and recognition:** Capturing video frames, detecting faces, and comparing their encodings to the `encodeListKnown` to identify individuals.\n",
    "- **Image-based face recognition:** Processing images, detecting faces, and comparing their encodings to the `encodeListKnown` to identify individuals in the images.\n",
    "\n",
    "By creating a database of known face encodings, the system can effectively recognize individuals and perform various tasks like attendance tracking, access control, or security surveillance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c7c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the webcam and recognize faces in real-time\n",
    "cap = cv2.VideoCapture(0)  # Assuming webcam index is 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    img = cv2.flip(img, 1)  # Flip the image horizontally (optional)\n",
    "\n",
    "    # Resize frame for faster face recognition processing\n",
    "    img_small = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    img_small = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find all face locations and face encodings in the current frame\n",
    "    faces_cur_frame = face_recognition.face_locations(img_small)\n",
    "    encodings_cur_frame = face_recognition.face_encodings(img_small, faces_cur_frame)\n",
    "\n",
    "    # Loop through each face found in the frame\n",
    "    for encode_face, face_loc in zip(encodings_cur_frame, faces_cur_frame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encode_face)\n",
    "        face_dis = face_recognition.face_distance(encodeListKnown, encode_face)\n",
    "\n",
    "        # Find the best match\n",
    "        match_index = np.argmin(face_dis)\n",
    "\n",
    "        if matches[match_index]:\n",
    "            name = classNames[match_index].upper()\n",
    "\n",
    "            # Scale the face location back up since we resized the frame\n",
    "            top, right, bottom, left = face_loc\n",
    "            top, right, bottom, left = top * 4, right * 4, bottom * 4, left * 4\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the name of the person\n",
    "            cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "            # Call your markAttendance function here\n",
    "            markAttendece(name)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # Exit on pressing 'Esc'\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68cbad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ea987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d81814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf294f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
